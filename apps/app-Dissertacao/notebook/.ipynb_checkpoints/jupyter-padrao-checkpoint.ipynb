{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Logo_CVM.png\" width=\"300\">\n",
    "\n",
    "<h1> Projeto xx - (SisCRI) - Sistema de Crítica de Regulamento Inicial</h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autor: Luiz Perciliano** - \n",
    "***LuizPerciliano@cvm.gov.br***\n",
    "- Dados do dia 15-05-2021\n",
    "- Baixando dados do SQL Server\n",
    "- Mesclando dataframes e agrupando dados\n",
    "- Visualização estatística\n",
    "\n",
    "\n",
    "**Requisitos Solicitados**\n",
    "- RF01 - Comparar Nome do Fundo\n",
    "- RF02 - Comparar o Público Alvo do Fundo\n",
    "- RF03 - Comparar a Prazo de Cotização\n",
    "- RF04 - Comparar a Prazo de Pagamento do Resgate\n",
    "- RF05 - Comparar o Prazo de Carência para o Resgate\n",
    "\n",
    "**Resumo**\n",
    "- Trabalhando apenas com registros a partir do ano 2018, somente PDF sem OCR. \n",
    "\n",
    "Site do projeto: https://cvmgovbr.sharepoint.com/sites/SistemadeCrticadeRegulamentoInicial\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Preparando a Infraesrtutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'Caminho que o jupyter está trabalhando:')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## pegar a hora de inicio do script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importar as bibliotecas necessárias e mapear a pasta do projeto.\n"
     ]
    }
   ],
   "source": [
    "print(f'Importar as bibliotecas necessárias e mapear a pasta do projeto.')\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_inicio = pd.Timestamp.now()\n",
    "print(data_inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(f'Importar documentos necessários para o projeto. (stopwords, etc)')\n",
    "\n",
    "#arquivo de controle para conferencia dos OCRs e retirar esses do projeto\n",
    "\n",
    "# carregar stop_words padrao no git e sempre pegar de lá para demais projetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'Lista do conteúdo da pasta ...')\n",
    "os.listdir(os.path.join('..','data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Verificar, atualizar e instalar se necessário python e módulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "## versao 3,9,0 estava funcionando\n",
    "print('Local de instalação do Python:       ',sys.executable)\n",
    "print('Versão do Python instalado e em uso: ',sys.version)\n",
    "print('Informações da versão do Python:     ',sys.version_info)\n",
    "print(f'Quantidade de CPU:                   {os.cpu_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print('Atualizando os módulos Python.')\n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print('Local de instalação do Python:       ',sys.executable)\n",
    "print('Versão do Python instalado e em uso: ',sys.version)\n",
    "print('Informações da versão do Python:     ',sys.version_info)\n",
    "print(f'Quantidade de CPU:                   {os.cpu_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print('Instalando os módulos necessários.')\n",
    "# print('')\n",
    "#!pip install Unidecode -q\n",
    "#!pip install sklearn\n",
    "#!pip install wordcloud\n",
    "#!pip install wget\n",
    "#!pip install opencv-python #import cv2\n",
    "#!pip install wand #wand=0.6.5\n",
    "#!pip install jupyter_contrib_nbextensions\n",
    "#!pip install pip-chill ## para verificar todos os mõdulos instalados para uma nova instalacao"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "print('Gerar arquivo com as dependencias necessárias para o projeto.')\n",
    "#import pip-chill\n",
    "#pip install -r > requirements.txt\n",
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print('Última atualização: ',(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando a infraestrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Criando as variáveis para o projeto.')\n",
    "## ????testar com novo caminho xxxx ????? -- path_pasta_trab = os.path.join('SisCRI','data')\n",
    "\n",
    "#pasta_trab = os.path.join('SisCRI','data','')\n",
    "pasta_trab = 'C:\\\\Users\\\\luizp\\\\jupyter-notebook\\\\SisCRI\\\\data\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando a base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão e consulta ao SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Criando as variáveis para coneção com base de dados.')\n",
    "servidor = 'CD-SQLDWP-01'\n",
    "banco = 'RICOH'\n",
    "info_conec = f'DRIVER={{SQL Server}}; server={servidor};database = {banco};Trusted_Connection=yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('''\n",
    "Criando a função para coneção com base de dados.\n",
    "Faz a conexão com o banco de dados, com o acesso da VPN habilitado:\n",
    "    Parâmetros:\n",
    "        - banco: base de dados\n",
    "        - servidor: servidor onde está disponível a base de dados\n",
    "    ''')\n",
    "def conecta_banco(banco,servidor):\n",
    "    info_conec = f'DRIVER={{SQL Server}}; server={servidor};database = {banco};Trusted_Connection=yes'\n",
    "    con = pyodbc.connect(info_conec)\n",
    "    cursor = con.cursor()\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('Criação da variável que recebe a execucão da função conecta banco. \\n'\n",
    "      'Para executar executar este comando, tem que estar com a VPN conectada.')\n",
    "con = conecta_banco(banco,servidor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('Criando variável que conterá a query que será executada no banco de dados.')\n",
    "## verificar funcao pd.read_sql\n",
    "consulta_links = dedent(\"\"\"                        \n",
    "                SELECT  *\n",
    "                FROM [RICOH].[ccd].[Fundo_Regulamento_Extrato_Inicial]\n",
    "                where Extensao_Arquivo_Regulamento = 'pdf';\n",
    "                                 \"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('Criando a função que executa query e carrega dasdos em um dataframe.')\n",
    "def executa_query(tsql,con):\n",
    "    '''Executa uma query em base de dados\n",
    "        Parâmetros:\n",
    "        - tsql - query que será executada -- ?????\n",
    "        - con - conexão estabelecida com a base de dados\n",
    "    '''\n",
    "    dataframe = pd.read_sql(tsql,con)\n",
    "    return dataframe   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Função que carrega as informacóes da query para um dataframe\n",
    "print('Criação do dataframe que recebe os dados a partir da execucão da função executa query. \\n'\n",
    "      'Para este caso, as temporárias devem estar criadas no banco de dados')\n",
    "raw_links_regulamentos_fundos = executa_query(consulta_links,con) # dataframe criado com a consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "df_plan_producao = pd.read_excel('C:/Users/luizp/jupyter-notebook/SisCRI/data/base-site-siscri.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando os dados brutos do dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 200)\n",
    "#pd.set_option(\"max_colwidth\", 40) # apresenta 40 palavras ou linhas da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Visualização do dataframe.')\n",
    "raw_links_regulamentos_fundos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verificando tipos e se tem dados nulos')\n",
    "raw_links_regulamentos_fundos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_links_regulamentos_fundos.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar campos nulos\n",
    "raw_links_regulamentos_fundos.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verificar colunas')\n",
    "#%timeit \n",
    "raw_links_regulamentos_fundos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copiar dataframe para ajustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_regulamentos_fundos = raw_links_regulamentos_fundos.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificar se os dataframes nao s\"ao espelhos\n",
    "print(id(links_regulamentos_fundos), id(raw_links_regulamentos_fundos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo as colunas de datas para o formato datetime\n",
    "colunas_datas = links_regulamentos_fundos.columns[links_regulamentos_fundos.columns.str.contains('DT_|dt\\|data|DATA|Data', regex=True)]\n",
    "colunas_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo cada coluna de colunas_datas para o formato datetime\n",
    "for coluna in colunas_datas:\n",
    "    links_regulamentos_fundos[coluna] = pd.to_datetime(links_regulamentos_fundos[coluna], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ajustar tipagem dos dados')\n",
    "links_regulamentos_fundos['Publico_Alvo_Extrato'] = links_regulamentos_fundos['Publico_Alvo_Extrato'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verificando tipos ajustados e dados nulos')\n",
    "links_regulamentos_fundos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### analisar estes números máximos e mínimos ?????????\n",
    "print('Resumo Estatístico de Campos Numéricos')\n",
    "links_regulamentos_fundos.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - Carregar plan de producao\n",
    "2 - Verficar entre os dfs \"links_regulamentos_fundos\" e \"df_plan_producao\" quais regulamentos sao novos\n",
    "3 - criar um DF só de regulamentos novos \"df_regulamentos_novos\" \n",
    "4 - este \"df_regulamentos_novos\" que deverá ser executado nos scripts abaixo\n",
    "depois pensamos em melhores nomes para os dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Algumas Visualizações para análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "### Gerando gráfico\n",
    "\n",
    "#variáveis do gráfico\n",
    "titulo = 'Datas X Quantidade de Regulamentos'\n",
    "eixo_x = 'Quantidade de Regulamentos'\n",
    "eixo_y = 'Datas em Anos'\n",
    "data_hora = datetime.datetime.now()\n",
    "path = os.path.join('..','image')\n",
    "img_extensao = '.png'\n",
    "image = 'data_regulamento'\n",
    "\n",
    "# Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "plt.plot(links_regulamentos_fundos['DATA_RECEBIMENTO_RI'])\n",
    "\n",
    "#Legendas e eixos\n",
    "#ax.legend(title='Legenda', loc=4, fontsize=20)\n",
    "ax.set_title(titulo, fontsize=20)\n",
    "ax.set_xlabel(eixo_x, fontsize=15)\n",
    "ax.set_ylabel(eixo_y, fontsize=15)\n",
    "plt.yticks(rotation=45) ## agrupar datas por meses, trimestre ou ano, etc\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "#Salvar imagem\n",
    "plt.savefig(path+image, dpi=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "# gerando o grafico de dispersao (Scatter) para analise preliminar dos dados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "source": [
    "### Gerando gráfico Tipo de Extensões\n",
    "\n",
    "#variáveis do gráfico\n",
    "titulo = 'Quantidade de Regulamentos e Extensões de arquivos'\n",
    "eixo_x = 'Tipos de extensões'\n",
    "eixo_y = 'Quantidade de Regulamentos'\n",
    "data_hora = datetime.datetime.now()\n",
    "path = os.path.join('..','image')\n",
    "img_extensao = '.png'\n",
    "image = ''\n",
    "\n",
    "# Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.bar(links_regulamentos_fundos['TP_EXTENSAO'].value_counts().index, links_regulamentos_fundos['TP_EXTENSAO'].value_counts())\n",
    "\n",
    "#Legendas e eixos\n",
    "#ax.legend(title='Legenda', loc=4, fontsize=20)\n",
    "ax.set_title(titulo, fontsize=20)\n",
    "ax.set_xlabel(eixo_x, fontsize=15)\n",
    "ax.set_ylabel(eixo_y, fontsize=15)\n",
    "plt.yticks(rotation=45) ## agrupar datas por meses, trimestre ou ano, etc\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "#Salvar imagem\n",
    "#plt.savefig(path+image, dpi=300)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "### Gerando gráfico - Público Alvo\n",
    "\n",
    "#variáveis do gráfico\n",
    "titulo = 'Quantidade de Regulamentos e Público Alvo'\n",
    "eixo_x = 'Público Alvo'\n",
    "eixo_y = 'Quantidade de Regulamentos'\n",
    "data_hora = datetime.datetime.now()\n",
    "path = os.path.join('..','image')\n",
    "img_extensao = '.png'\n",
    "image = ''\n",
    "\n",
    "# Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.bar(links_regulamentos_fundos['PUBLICO_ALVO_EI'].value_counts().index, links_regulamentos_fundos['PUBLICO_ALVO_EI'].value_counts())\n",
    "\n",
    "#Legendas e eixos\n",
    "#ax.legend(title='Legenda', loc=4, fontsize=20)\n",
    "ax.set_title(titulo, fontsize=20)\n",
    "ax.set_xlabel(eixo_x, fontsize=15)\n",
    "ax.set_ylabel(eixo_y, fontsize=15)\n",
    "plt.yticks(rotation=45) ## agrupar datas por meses, trimestre ou ano, etc\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "#Salvar imagem\n",
    "#plt.savefig(path+image, dpi=300)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "## ajustar pra ranq de 10 +\n",
    "\n",
    "\n",
    "### Gerando gráfico\n",
    "\n",
    "#variáveis do gráfico\n",
    "titulo = 'Quantidade de Regulamentos e Administradoras'\n",
    "eixo_x = 'Administradoras'\n",
    "eixo_y = 'Quantidade de Regulamentos'\n",
    "data_hora = datetime.datetime.now()\n",
    "path = os.path.join('..','image')\n",
    "img_extensao = '.png'\n",
    "image = ''\n",
    "\n",
    "# Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "plt.bar(links_regulamentos_fundos['NOME_ADMINISTRADORA'].value_counts().index, links_regulamentos_fundos['NOME_ADMINISTRADORA'].value_counts())\n",
    "\n",
    "#Legendas e eixos\n",
    "#ax.legend(title='Legenda', loc=4, fontsize=20)\n",
    "ax.set_title(titulo, fontsize=20)\n",
    "ax.set_xlabel(eixo_x, fontsize=15)\n",
    "ax.set_ylabel(eixo_y, fontsize=15)\n",
    "plt.yticks(rotation=45) ## agrupar datas por meses, trimestre ou ano, etc\n",
    "plt.xticks(rotation=90) ## Colocar o nome dentro do gráfico\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "#Salvar imagem\n",
    "#plt.savefig(path+image, dpi=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "print('Visão geral em gráfico')\n",
    "sns.pairplot(links_regulamentos_fundos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "# comparar com histograma - obs, para histograma tem q estar na forma de número\n",
    "# ver qt de dias do registro para o primeiro regulamento\n",
    "# ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links_regulamentos_fundos.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# exportar dataframe para excel\n",
    "xlsx = links_regulamentos_fundos.to_excel(r'C:\\Users\\luizp\\jupyter-notebook\\SisCRI\\data\\regulamentos.xlsx',index=True, encoding='utf-8', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegar os dados do dataframe e carregar na pasta do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Alguns possíveis testes:\n",
    "    ## para ver se o servidor onde está o arquivo está de pé\n",
    "    ## verificar se arquivo já existe\n",
    "    ## confundi o nome com docX, nao seria interessante ajustar o nome\n",
    "    ## ?? Tratar se os arquivos já existirem, pois ele cria novamente com + 1 cópia, ou excluir estes ao final.\n",
    "## ?  colocar um timeit ou loading, colocar aviso que terminou e qts docs foram importados\n",
    "## +- 10 minutos para baixar 1000 pdfs\n",
    "\n",
    "print('Criar função que pega os PDFs a partir do dataframe carregado e coloca na pasta do projeto.')\n",
    "def download_doc(pasta_pdf,base_links):\n",
    "    '''Faz o download do arquivo em um link da Web\n",
    "        Parâmetros:\n",
    "        - pasta_pdf: pasta onde serao armazenados os arquivos em pdf para conversao\n",
    "        - base_links: dataframe com os links dos documentos que serão baixados.\n",
    "        O campo LINK_ARQ indica o caminho onde os arquivos estão armazenados\n",
    "    '''\n",
    "    os.chdir(pasta_pdf)\n",
    "    for link in base_links['Link_Download_Regulamento']:\n",
    "        if link != None:           \n",
    "            wget.download(link)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Funcão que baixa os documentos do link para pasta do projeto\n",
    "print('Executa a função que pega os PDFs do dataframe e coloca na pasta do projeto.')\n",
    "download_doc(pasta_origem,links_regulamentos_fundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Verificar quantidade de arquivos na pasta pdf. Download em +- xx minutos')\n",
    "list = os.listdir(\"C:/Users/luizp/jupyter-notebook/SisCRI/data/pdf/\")\n",
    "number_files = len(list)\n",
    "print (number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# tentar identificar quais pdfs sao ou tem ocr, criar uma coluna no dataframe e nao carregar estes ?????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar e extrair textos dos PDFs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## separar bem cada funcao para tratar cada tipo de arquivo e, depois, talvez, criar uma q chama todas as outras\n",
    "ver possibilidade de ter duas funcoes, uma para ler com OCR e outra sem OCR\n",
    "\n",
    "Remover os OCRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('Criaçao de função que melhora o tratamento de imagens, usada na função \"Leitura_pdf\".')\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('Criaçao de função que melhora o tratamento de imagens , usada na função \"Leitura_pdf\".')\n",
    "def remove_noise2(image):\n",
    "    return cv2.GaussianBlur(image,(5,5),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Ler Pasta com conteúdo de documentos\n",
    "## ???? vai no dataframe, na pasta? ou na pasta normalizada?\n",
    "print('Criando a função que vai no dataframe, pega os links dos documentos e converte os documentos para txt.')\n",
    "def Ler_pasta(pasta_trab, sep, resolucao, links_regulamentos_fundos):\n",
    "    ''' Leitura do dataframe onde será lido os documentos e convertidos para txt\n",
    "        Parâmetros:\n",
    "        - resolucao: resolucao que será utilizada para gravação dos arquivos.jpg\n",
    "        - links_regulamentos_fundos: dataframe que contem os arquivos de regulamentos que deverão ser convertidos\n",
    "    ''' \n",
    "    pasta_txt = pasta_trab + 'txt' + sep\n",
    "    pasta_jpg = pasta_trab + 'jpg' + sep\n",
    "    pasta_origem = pasta_trab+'pdf'+sep\n",
    "    os.chdir(pasta_origem)\n",
    "    erros_leitura = [] # lista de flags de leitura mal sucedida\n",
    "    escaneados = [] # lista de flags de alguma página escaneada\n",
    "    for i, arq in enumerate(links_regulamentos_fundos['Nome_Arquivo_Regulamento']):\n",
    "            if arq != None:\n",
    "                try:\n",
    "                    arq_sem_extensao, extensao = os.path.splitext(arq)\n",
    "                    if extensao == \".doc\":     # arquivos que são .doc\n",
    "                        flag_erro = Leitura_doc(pasta_origem,pasta_txt,arq_sem_extensao,sep)\n",
    "                        flag_scan = False\n",
    "                        escaneados.append(flag_scan)\n",
    "                        erros_leitura.append(flag_erro)\n",
    "                    elif extensao == \".pdf\":    \n",
    "                        (flag_scan, flag_erro) = Leitura_pdf(pasta_origem,pasta_txt,pasta_jpg, arq_sem_extensao, resolucao)\n",
    "                        escaneados.append(flag_scan)\n",
    "                        erros_leitura.append(flag_erro)           \n",
    "                    else:\n",
    "                        escaneados.append('extensao nao tratada')\n",
    "                        erros_leitura.append('extensao nao tratada')\n",
    "                except OSError:\n",
    "                    escaneados.append('sem arquivo')\n",
    "                    erros_leitura.append('sem arquivo')\n",
    "            else:\n",
    "                escaneados.append('sem link')\n",
    "                erros_leitura.append('sem link')\n",
    "    # dataframe de controle\n",
    "    controle = pd.DataFrame({'arq': links_regulamentos_fundos['Link_Download_Regulamento'].values, 'scan': escaneados,\n",
    "                                'erro': erros_leitura})\n",
    "    os.chdir(pasta_trab)\n",
    "    controle.to_csv('controle.csv', sep=';', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# este projeto nao trabalhará com .doc\n",
    "## ????? a pasta origem nao podia ter um nome diferente de PDF?\n",
    "\n",
    "print('Criar função para tratamento de arquivos \".doc\", esta funcão será lida pela \"Leitura_pdf\".')\n",
    "def Leitura_doc(pasta_origem,pasta_txt,arq_sem_extensao,sep):    \n",
    "    ''' Conversao dos arquivos .doc\n",
    "        Parâmetros: \n",
    "        - pasta_origem: pasta onde estao armazenados os arquivos que serão convertidos??? vem do dataframe\n",
    "        - pasta_txt: pasta onde serao armazenados os arquivos convertidos\n",
    "        - arq_sem_extensao: nome do arquivo (sem o .doc) -- ????\n",
    "    '''\n",
    "    flag_erro=False\n",
    "    try:\n",
    "        arq=arq_sem_extensao+'.doc'\n",
    "        content = textract.process(os.path.join(pasta_origem,arq))\n",
    "        dest_file=arq_sem_extensao+\".txt\"\n",
    "        write_text_file = open(os.path.join(pasta_txt, dest_file), \"wb\")\n",
    "        write_text_file.write(content)\n",
    "        write_text_file.close()\n",
    "    except:\n",
    "        flag_erro=True\n",
    "    return flag_erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print('Criando a função que lê os PDFs.')\n",
    "def Leitura_pdf(pasta_origem, pasta_txt, pasta_jpg, arq_sem_extensao, resolucao):\n",
    "    '''Transforma o pdf em txt, verificando se suas páginas são pesquisáveis ou escaneadas.\n",
    "        Usa PyMuPDF para ler pdfs pesquisáveis e Tesseract para escaneadas.\n",
    "        Grava págs escaneadas em jpg.\n",
    "        Gera df de controle. As colunas de erros de leitura e de ocorrência de scan levam a\n",
    "        string \"sem link\" caso o banco de metadados não traga o link. --????\n",
    "       \n",
    "       Parâmetros:\n",
    "        - pasta_origem: pasta onde estao armazenados os arquivos que serão convertidos\n",
    "        - pasta_txt: pasta onde serao armazenados os arquivos convertidos\n",
    "        - pasta_jpg: pasta onde serao armazenados os arquivos pdf escaneados\n",
    "        - arq_sem_extensao: nome do arquivo (sem o .pdf) ---????\n",
    "        - resolucao: resolucao que será utilizada para gravação dos arquivos.jpg\n",
    "    '''\n",
    "    \n",
    "    ##flag_scan = False # sinaliza se página é não pesquisável e liga scanner só uma vez\n",
    "    flag_scan = False\n",
    "    flag_erro = False # sinaliza se houve erro na leitura\n",
    "    page_num = 0 # número da página\n",
    "    texto_lido = \"\" # texto lido pelo sistema, junta páginas pesquisáveis e escaneadas\n",
    "    try:\n",
    "        #path_pdf = path completo, com todas as pastas, do PDF do relatório\n",
    "        path_pdf=pasta_origem+arq_sem_extensao+'.pdf'\n",
    "        #path_txt = path completo dos arquivos .txt convertidos\n",
    "        path_txt=pasta_txt+arq_sem_extensao+'.txt'\n",
    "        \n",
    "        doc = fitz.open(path_pdf)\n",
    "        for page in doc:\n",
    "            page_num += 1\n",
    "            texto = page.getText() # leitura pelo PyMuPDF\n",
    "            if len(texto) < 10 and not flag_scan:\n",
    "                # leitura do PyMuPDF provavelmente ruim, documento será escaneado pelo Wand só uma vez\n",
    "                path_jpg=pasta_jpg+arq_sem_extensao+'.jpg'\n",
    "                flag_scan = True\n",
    "                # geracao do jpg com a utilizacao do Wand\n",
    "                with Img(filename = path_pdf, resolution = resolucao) as pdfimg:\n",
    "                        pdfimg.compression_quality = 99\n",
    "                        pdfimg.despeckle()\n",
    "                        pdfimg.save(filename = path_jpg) # grava todas as págs escaneadas\n",
    "                # apenas a página corrente do loop que não conseguiu ser lida pelo fitz\n",
    "                pag_emarquivo = path_jpg[:-4] + '-' + str(page_num - 1) + '.jpg'\n",
    "                image = Image.open(pag_emarquivo).convert(\"RGB\") # imagem da página escaneada\n",
    "                #Melhoria da qualidade da imagem para prossecamento pelo tesseract\n",
    "                opt_image=np.array(image)\n",
    "                opt_image = remove_noise(opt_image) \n",
    "                opt_image = remove_noise2(opt_image)\n",
    "                custom_config = r'--oem 3 --psm 3'\n",
    "                escaneado=ocr.image_to_string(opt_image,config=custom_config,lang='por')\n",
    "                if len(escaneado) > len(texto):\n",
    "                    texto_lido += escaneado + ' '\n",
    "                else:\n",
    "                    texto_lido += texto + ' '\n",
    "            elif len(texto) < 10 and flag_scan:\n",
    "                path_jpg=pasta_jpg+arq_sem_extensao+'.jpg'\n",
    "                \n",
    "            # leitura do PyMuPDF provavelmente ruim, buscar página escaneada anteriormente em arquivo\n",
    "                \n",
    "                pag_emarquivo = path_jpg[:-4] + '-' + str(page_num - 1) + '.jpg'\n",
    "                \n",
    "                image = Image.open(pag_emarquivo).convert(\"RGB\") # imagem da página escaneada\n",
    "                opt_image=np.array(image)\n",
    "                opt_image = remove_noise(opt_image) \n",
    "                opt_image = remove_noise2(opt_image)\n",
    "                custom_config = r'--oem 3 --psm 3'\n",
    "                escaneado=ocr.image_to_string(opt_image,config=custom_config,lang='por')\n",
    "                if len(escaneado) > len(texto):\n",
    "                    texto_lido += escaneado + ' '\n",
    "                else:\n",
    "                    texto_lido += texto + ' '\n",
    "                \n",
    "            elif len(texto) >= 10: # leitura do PyMuPDF provavelmente bem-sucedida\n",
    "                texto_lido += page.getText()\n",
    "        # salvar o arquivo txt (mesmo nome do PDF) com o resultado da leitura\n",
    "        \n",
    "        fid = open(path_txt, \"w\", encoding = 'utf-8')\n",
    "        fid.write(texto_lido)\n",
    "        fid.close()\n",
    "    except:\n",
    "        flag_erro = True\n",
    "    return (flag_scan, flag_erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## ????? Lê a pasta ou o dataframe, pois na pasta tinha uma quantidade x e só ccarregou do dataframe????\n",
    "    ## parece q sõ le o df\n",
    "\n",
    "\n",
    "\n",
    "# Funcão que lê a pasta de trabalho e converte documentos para txt\n",
    "## acho interessante ter uma funcao q verifica se tem os ocrs e trata só estes, ou seja, cria apenas as imagens\n",
    "# Se ele processa do dataframe, nao seria interessante ajustar o nome da função\n",
    "## ??? mupdf: aviso\n",
    "    ## deu ruim no arquivo \"20210122191528UP3f88b2f1d5c24c0b995d96d5306f1680 (1).pdf\" - arquivo com falha na origem\n",
    "print('Chamada principal que processa os documentos DO DATAFRAME e cria os txts.')\n",
    "Ler_pasta(pasta_trab, sep, resolucao, links_regulamentos_fundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "print('Verificar quantidade de arquivos na pasta txt. Rodou em 8h e 27 minutos')\n",
    "list = os.listdir(\"C:/Users/luizp/jupyter-notebook/SisCRI/data/txt/\")\n",
    "number_files = len(list)\n",
    "print (number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verificar quantidade de arquivos na pasta jpg.')\n",
    "list = os.listdir(\"C:/Users/luizp/jupyter-notebook/SisCRI/data/jpg/\")\n",
    "number_files = len(list)\n",
    "print (number_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega documentos txts para dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# aqui vai carregar tudo que está na pasta e não somente os que foram transformados\n",
    "print('''\n",
    "    Carregar os documentos txts processados em um dataframe apenas com a coluna de texto.\n",
    "    Criado uma lista vazia allLines, lido o conteúdo do diretorio txt e add nesta lista.\n",
    "''')\n",
    "\n",
    "# Criação de Lista vazia\n",
    "allLines = []\n",
    "\n",
    "# variável q contém o dirtório com os arquivos txts para carga\n",
    "path = 'C:/Users/luizp/jupyter-notebook/SisCRI/data/txt/'\n",
    "\n",
    "# variável com a lista de todos os arquivos txts\n",
    "fileList = os.listdir(path)\n",
    "\n",
    "# Loop\n",
    "for i in fileList:\n",
    "    file = open(os.path.join(path+ i), 'r', encoding='UTF-8')\n",
    "    #allLines.append(file.read().strip())\n",
    "    allLines.append(file.read().strip().replace(\"\\n\",\" \"))\n",
    "\n",
    "# Criado dicionário com: nome do arquivo em uma coluna e na outra o conteúdo do arquivo\n",
    "dados = {\n",
    "    \"nome_arquivo\": fileList,\n",
    "    \"texto\": allLines\n",
    "}\n",
    "\n",
    "# Criado dataframe com o conteúdo do dicionário\n",
    "raw_data = pd.DataFrame(dados)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verificar dados únicos')\n",
    "raw_data.nome_arquivo.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar campos nulos\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unir dfs - estruturado + texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unir os dataframes e tratar o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Verificando tipos e se tem dados nulos')\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## criar uma cópia do raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Passar coluna nome do arquivo para lower')\n",
    "#raw_data['nome_arquivo'] = raw_data.lower(['nome_arquivo'] )\n",
    "raw_data[\"nome_arquivo\"] = raw_data[\"nome_arquivo\"].apply(lambda x: x.lower())\n",
    "links_regulamentos_fundos[\"Nome_Arquivo_Regulamento_Sem_Extensao\"] = links_regulamentos_fundos[\"Nome_Arquivo_Regulamento_Sem_Extensao\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alterar nome do arquivo, tirando a extensao e o ponto, para fazer merge de dataframes')\n",
    "#raw_data['nome_arquivo'] = raw_data['nome_arquivo'].apply(lambda x: x[:-4])\n",
    "#raw_data['nome_arquivo'] = raw_data['nome_arquivo'].str.replace('.txt','')\n",
    "#raw_data['nome_arquivo'].str.rstrip('.txt')\n",
    "\n",
    "raw_data['nome_arquivo'] = raw_data['nome_arquivo'].str.replace('.txt','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_regulamentos_fundos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## criar um dataframe q une o links_regulamentos_fundos + allLines, ligados pelo nome do arquivo\n",
    "merged_inner = pd.merge(left=links_regulamentos_fundos, right=raw_data, left_on='Nome_Arquivo_Regulamento_Sem_Extensao', right_on='nome_arquivo', suffixes=[\"_links_regulamentos_fundos\", \"_raw_data\"])\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar dataframe geral para excel\n",
    "xlsx = data.to_excel(r'C:\\Users\\luizp\\jupyter-notebook\\SisCRI\\data\\regulamentos_X_extrato.xlsx',index=True, encoding='utf-8', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REQ001 - Nome do Fundo -  RI X EI (tabela SIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Remover ruídos em todo o corpus.')\n",
    "#pontuacao = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}',\"%\"]\n",
    "\n",
    "#remove números e caracteres especiais\n",
    "data[\"texto\"] = data[\"texto\"].apply(lambda x: re.sub('\\?|\\*|;|,|\\.|-|–|:|\"|•', '', x))\n",
    "data[\"Nome_Fundo\"] = data[\"Nome_Fundo\"].apply(lambda x:   re.sub('\\?|\\*|;|,|\\.|-|–|:|\"|•', '', x))\n",
    "data[\"Publico_Alvo_Extrato\"] = data[\"Publico_Alvo_Extrato\"].apply(lambda x:   re.sub('\\?|\\*|;|,|\\.|-|–|:|\"|•', '', x))\n",
    "\n",
    "#remove acentos \n",
    "data[\"texto\"] = data[\"texto\"].apply(lambda x: unidecode(x))\n",
    "data[\"Nome_Fundo\"] = data[\"Nome_Fundo\"].apply(lambda x: unidecode(x))\n",
    "data[\"Publico_Alvo_Extrato\"] = data[\"Publico_Alvo_Extrato\"].apply(lambda x: unidecode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Nome_Fundo'] =   data['Nome_Fundo'].str.replace('INVEST ', ' INVESTIMENTO ').str.replace(' FI ', ' FUNDO DE INVESTIMENTO ').str.replace('FICFI', ' FUNDO DE INVESTIMENTO EM COTAS DE FUNDOS DE INVESTIMENTO ').str.replace('FIC ', ' FUNDO DE INVESTIMENTO EM COTAS ').str.replace('FDO', ' FUNDO ').str.replace(' LP', ' LONGO PRAZO ').str.replace('INV ', ' INVESTIMENTO ').str.replace(' IE', ' INVESTIMENTO NO EXTERIOR ').str.replace(' FIA ', ' FUNDO DE INVESTIMENTO EM ACOES ').str.replace('CRED ', 'CREDITO ').str.replace('PRIV ', ' PRIVADO ').str.replace('FIM ', ' FUNDO DE INVESTIMENTO MULTIMERCADO ').str.replace(' FUNDOS ', ' FUNDO ').str.replace(' S ', ' ').str.replace('  ', ' ')\n",
    "data['texto'] = data['texto'].str.replace('INVEST ', ' INVESTIMENTO ').str.replace(' FI ', ' FUNDO DE INVESTIMENTO ').str.replace('FICFI', ' FUNDO DE INVESTIMENTO EM COTAS DE FUNDOS DE INVESTIMENTO ').str.replace('FIC ', ' FUNDO DE INVESTIMENTO EM COTAS ').str.replace('FDO', ' FUNDO ').str.replace(' LP', ' LONGO PRAZO ').str.replace('INV ', ' INVESTIMENTO ').str.replace(' IE', ' INVESTIMENTO NO EXTERIOR ').str.replace(' FIA ', ' FUNDO DE INVESTIMENTO EM ACOES ').str.replace('CRED ', 'CREDITO ').str.replace('PRIV ', ' PRIVADO ').str.replace('FIM ', ' FUNDO DE INVESTIMENTO MULTIMERCADO ').str.replace(' FUNDOS ', ' FUNDO ').str.replace(' S ', ' ').str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar resultados - nome do fundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para melhor análise, deixar tbm o nome do arquivo\n",
    "data[\"Nome_Fundo_Encontrado\"] = data.apply(lambda x:x.Nome_Fundo in x.texto, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## identificando apenas os casos falsos\n",
    "data_false = data.loc[data['Nome_Fundo_Encontrado'] == False]\n",
    "data_false.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportação do resultado para Excel traumáticos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## verificar a forma do campo regulamento levar somente uma qtd específica de texto\n",
    "## passar apenas os falses para melhor análise\n",
    "xlsx = data_false.to_excel(r'C:\\Users\\luizp\\jupyter-notebook\\SisCRI\\data\\REQ-001-nome-fundo-analisar.xlsx',index=True, encoding='utf-8', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## planilha geral\n",
    "xlsx = data.to_excel(r'C:\\Users\\luizp\\jupyter-notebook\\SisCRI\\data\\REQ-001-nome-fundo-geral.xlsx',index=True, encoding='utf-8', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REQ002 - Público Alvo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## ir para o arquivo http://localhost:8889/notebooks/jupyter-notebook/SISCRI-ML/relatorio-jupyter/SisCRI_ML_v7.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fim = pd.Timestamp.now()\n",
    "print(data_inicio)\n",
    "print(data_fim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {
    "height": "757px",
    "left": "1536px",
    "top": "110px",
    "width": "504px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
